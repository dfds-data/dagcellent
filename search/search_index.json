{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to \u2728Dagcellent","text":"<p>Dagcellent is a library, which contains reusable components to work with Apache Airflow. It is designed to make the development of Airflow DAGs easier and more efficient.</p> <p>Some of the features of Dagcellent are:</p> <ul> <li>Dynamic DAGs: Create DAGs dynamically.</li> <li>DAG from config: Create DAGs from a configuration file.</li> <li>many more are coming!</li> </ul> <p>Check out the Reference page for a full list of operators/modules.</p>"},{"location":"#note","title":"Note","text":"<p>The purpose of this page is to have a detailed reference documentation of the library. You will NOT find on this page detailed guides, tutorials. The following may help:</p> <ul> <li>Tutorials</li> <li>How-to-guides</li> </ul>"},{"location":"about/","title":"Why?","text":"<p>You might ask - why a separate package and not just shove everything into the <code>dags</code> folder of Airflow.</p> <p>That works for development. However, we are running more and more business-critical work-flows on Airflow. In order to ensure business continuity and reduce the risk of errors, we need more reliable and maintainable building blocks.</p> <ul> <li>Maintainability: You can reuse the components across multiple DAGs.</li> <li>Quality: This repository aims to set a new standard in the internal Python eco-system, hence we ensure<ul> <li>\u2728 High code-quality with aggressive linters and strict PR policies</li> <li>\u2712\ufe0f  Well-documented public API and examples</li> <li>\ud83d\udce6 Transparent release cycle</li> <li>\ud83e\uddea High test coverage</li> </ul> </li> <li>Reusability: You can reuse the components across multiple DAGs.</li> </ul> <p>Versioning</p> <p>The package follows semantic versioning. Breaking changes will occur unannounced before <code>v1.0.0</code>. After that all breaking changes will lead to bumping the major version number.</p>"},{"location":"about/#contact","title":"Contact","text":"<p>The project is hosted at github.com/dfds-data/dagcellent.</p> <p>If you have a feature request, noticed a bug - it is best to open a new issue on that page.</p>"},{"location":"reference/","title":"Index","text":"<p>API reference.</p> <p>Common Airflow dags and plugins for DFDS.</p> <p>Modules:</p> Name Description <code>dag</code> <p>Utilities related to DAGs and creating DAGs.</p> <code>data_utils</code> <p>Utilities related to handling various data sources e.g.: databases, cloud blob storage.</p> <code>operators</code> <p>Reusable operators to build Airflow DAGs.</p>"},{"location":"reference/dag/","title":"Dag","text":"<p>Utilities related to DAGs and creating DAGs.</p>"},{"location":"reference/dag/#dagcellent.dag.Config","title":"Config","text":"<p>               Bases: <code>BaseModel</code></p> <p>Default config definition.</p> <p>Attributes:</p> Name Type Description <code>version</code> <code>int</code> <p>(int) version of the parser</p> <code>description</code> <code>str | None</code> <p>(str) short description of the configs (for humans)</p>"},{"location":"reference/dag/#dagcellent.dag.Config.from_json","title":"from_json  <code>classmethod</code>","text":"<pre><code>from_json(file: Path) -&gt; T\n</code></pre> <p>Load from JSON file to Config object.</p> <p>Parameters:</p> Name Type Description Default <code>Path</code> <p>path to toml files.</p> required"},{"location":"reference/dag/#dagcellent.dag.Config.from_json(file)","title":"<code>file</code>","text":""},{"location":"reference/dag/#dagcellent.dag.Config.from_toml","title":"from_toml  <code>classmethod</code>","text":"<pre><code>from_toml(file: Path) -&gt; T\n</code></pre> <p>Load from TOML file to Config object.</p> <p>Parameters:</p> Name Type Description Default <code>Path</code> <p>path to toml files.</p> required"},{"location":"reference/dag/#dagcellent.dag.Config.from_toml(file)","title":"<code>file</code>","text":""},{"location":"reference/dag/#dagcellent.dag.parse_config_file","title":"parse_config_file","text":"<pre><code>parse_config_file(resource_paths: Iterable[Path], parser: Callable[..., T]) -&gt; list[T]\n</code></pre> <p>Parse config files.</p> <p>Parameters:</p> Name Type Description Default <code>Iterable[Path]</code> <p>file paths</p> required <code>Callable</code> <p>parsing logic</p> required"},{"location":"reference/dag/#dagcellent.dag.parse_config_file(resource_paths)","title":"<code>resource_paths</code>","text":""},{"location":"reference/dag/#dagcellent.dag.parse_config_file(parser)","title":"<code>parser</code>","text":""},{"location":"reference/data_utils/","title":"Data utils","text":"<p>Utilities related to handling various data sources e.g.: databases, cloud blob storage.</p>"},{"location":"reference/data_utils/#dagcellent.data_utils.Pyarrow2redshift","title":"Pyarrow2redshift","text":"<p>Map Apache Arrow to Redshift.</p>"},{"location":"reference/data_utils/#dagcellent.data_utils.Pyarrow2redshift.map","title":"map  <code>classmethod</code>","text":"<pre><code>map(dtype: DataType, string_type: str) -&gt; str\n</code></pre> <p>Pyarrow to Redshift data types conversion.</p>"},{"location":"reference/data_utils/#dagcellent.data_utils.UnsupportedType","title":"UnsupportedType","text":"<p>               Bases: <code>Exception</code></p> <p>Unsupported type exception.</p>"},{"location":"reference/data_utils/#dagcellent.data_utils.reflect_meta_data","title":"reflect_meta_data","text":"<pre><code>reflect_meta_data(engine: Engine, schema: str | None, table: str) -&gt; Table | None\n</code></pre> <p>Reflects the metadata from the engine.</p>"},{"location":"reference/data_utils/#dagcellent.data_utils.reflect_select_query","title":"reflect_select_query","text":"<pre><code>reflect_select_query(engine: Engine, table: Table) -&gt; Query\n</code></pre> <p>Reflect the select query from the meta data.</p>"},{"location":"reference/operators/","title":"Operators","text":"<p>Reusable operators to build Airflow DAGs.</p>"},{"location":"reference/operators/#dagcellent.operators.CreateExternalTableArrow","title":"CreateExternalTableArrow","text":"<pre><code>CreateExternalTableArrow(table_name: str, sql_conn_id: str, database: str, schema_name: str, s3_location: str, type_map: dict[str, str], partitioned: bool = False, force_drop: bool = False, external_schema_name: str = 'src', **kwargs: Any)\n</code></pre> <p>               Bases: <code>BaseOperator</code></p> <p>Generate SQL DDL to create external table in target database.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>The name of the table to create.</p> required <code>str</code> <p>The source connection id.</p> required <code>str</code> <p>The S3 location of the data.</p> required <code>bool</code> <p>If True, drop the table first. Defaults to False.</p> <code>False</code> <code>str</code> <p>The schema name. Defaults to \"src\".</p> <code>'src'</code> <code>bool</code> <p>Partition by <code>run_date</code>. Defaults to False.</p> <code>False</code> <p>Raises:</p> Type Description <code>AirflowException</code> <p>If the table does not exist in the source database</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Example <pre><code>create_external_table = CreateExternalTable(\n    task_id=\"create_external_table\",\n    table_name=\"my_table\",\n    sql_conn_id=\"my_conn\",\n    s3_location=\"s3://my-bucket/my-folder/\",\n    force_drop=True,\n)\n</code></pre>"},{"location":"reference/operators/#dagcellent.operators.CreateExternalTableArrow(table_name)","title":"<code>table_name</code>","text":""},{"location":"reference/operators/#dagcellent.operators.CreateExternalTableArrow(sql_conn_id)","title":"<code>sql_conn_id</code>","text":""},{"location":"reference/operators/#dagcellent.operators.CreateExternalTableArrow(s3_location)","title":"<code>s3_location</code>","text":""},{"location":"reference/operators/#dagcellent.operators.CreateExternalTableArrow(force_drop)","title":"<code>force_drop</code>","text":""},{"location":"reference/operators/#dagcellent.operators.CreateExternalTableArrow(external_schema_name)","title":"<code>external_schema_name</code>","text":""},{"location":"reference/operators/#dagcellent.operators.CreateExternalTableArrow(partitioned)","title":"<code>partitioned</code>","text":""},{"location":"reference/operators/#dagcellent.operators.SQLReflectOperator","title":"SQLReflectOperator","text":"<pre><code>SQLReflectOperator(*, table_name: str, database: str | None = None, schema: str | None = None, **kwargs: Any)\n</code></pre> <p>               Bases: <code>SQLExecuteQueryOperator</code></p> <p>Operator to perform SQLAlchemy like database reflection.</p> <p>The target_table is returned as a <code>SELECT</code> statement DDL.</p> Example <p>The example below illustrates a PostrgeSQL database and the returned SELECT query.</p> <pre><code>CREATE TABLE IF NOT EXISTS ats\n(\n    departure_id varchar(40) COLLATE pg_catalog.\"default\" NOT NULL,\n    route_leg_code varchar(40) COLLATE pg_catalog.\"default\" NOT NULL,\n    planned_departure_date_time timestamp without time zone NOT NULL,\n    ferry_name varchar(40) COLLATE pg_catalog.\"default\" NOT NULL,\n    cnv_outlet varchar(40) COLLATE pg_catalog.\"default\" NOT NULL,\n    store_name varchar(40) COLLATE pg_catalog.\"default\" NOT NULL,\n    store_item varchar(200) COLLATE pg_catalog.\"default\" NOT NULL,\n    predicted_sales double precision NOT NULL,\n    good boolean DEFAULT false,\n    CONSTRAINT ats_pkey PRIMARY KEY (departure_id, route_leg_code, ferry_name, cnv_outlet, store_name, store_item)\n);\n</code></pre> <pre><code>reflect_table = SQLReflectOperator(\n    table_name=\"ats\",\n    task_id=\"reflect_database\",\n    conn_id=CONN_ID,\n)\n</code></pre> <pre><code>SELECT\n    ats.departure_id,\n    ats.route_leg_code,\n    ats.planned_departure_date_time,\n    ats.ferry_name,\n    ats.cnv_outlet,\n    ats.store_name,\n    ats.store_item,\n    ats.predicted_sales,\n    ats.good\nFROM ats\n</code></pre> <p>Parameters:</p> Name Type Description Default <p>target table name</p> required <code>Any</code> <p>additional arguments to pass to SQLExecuteQueryOperator</p> <code>{}</code>"},{"location":"reference/operators/#dagcellent.operators.SQLReflectOperator(table)","title":"<code>table</code>","text":""},{"location":"reference/operators/#dagcellent.operators.SQLReflectOperator(kwargs)","title":"<code>kwargs</code>","text":""},{"location":"reference/operators/#dagcellent.operators.SqlToS3Operator","title":"SqlToS3Operator","text":"<pre><code>SqlToS3Operator(chunksize: int = 10 ** 6, fix_dtypes: bool = True, where_clause: str | None = None, join_clause: str | None = None, type_mapping: PyarrowMapping = Pyarrow2redshift, database: str | None = None, **kwargs: Any)\n</code></pre> <p>               Bases: <code>SqlToS3Operator</code></p> <p>Move data from SQL source to S3.</p> <p>Uses batching. Empty files are not written, which prevents breaking external tables in Redshift.</p> <p>Partitioning If the data is partitioned, <code>run_date=</code> partitions will be used.</p> <p>Until we have observability, we will not optimize/move away from the built-in provider (and pandas).</p> kwargs Example <p>Output query:</p> <pre><code>SELECT [EngineSourceKey]\n      ,[EngineSourceCode]\n      ,[EngineSourceName]\nFROM [dbo].[t_D_EngineSource];\n</code></pre>"},{"location":"reference/operators/#dagcellent.operators.SqlToS3Operator.file_options","title":"file_options  <code>property</code>","text":"<pre><code>file_options: FileOptions\n</code></pre> <p>Get the file options for the file format.</p>"},{"location":"reference/operators/#dagcellent.operators.SqlToS3Operator.partitioned","title":"partitioned  <code>property</code>","text":"<pre><code>partitioned: bool\n</code></pre> <p>Check if the file is partitioned.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the file is partitioned</p>"},{"location":"reference/operators/#dagcellent.operators.SqlToS3Operator.get_random_string","title":"get_random_string  <code>staticmethod</code>","text":"<pre><code>get_random_string(char_count: int = 10) -&gt; str\n</code></pre> <p>Given number of characters returns a random string with that length.</p> <p>:param char_count: number of characters :type char_count: int</p>"},{"location":"reference/operators.mlflow/","title":"MLFlow","text":"<p>This package wraps some functionalities of MLFlows life-cycle management features.</p> <p>MLflow Skinny: A Lightweight Machine Learning Lifecycle Platform Client.</p> <p>MLflow Skinny is a lightweight MLflow package without SQL storage, server, UI, or data science dependencies. MLflow Skinny supports:     Tracking operations (logging / loading / searching params, metrics, tags + logging / loading artifacts)     Model registration, search, artifact loading, and deployment     Execution of GitHub projects within notebook &amp; against a remote target.</p>"},{"location":"reference/operators.mlflow/#dagcellent.operators.mlflow.GetLatestModelVersion","title":"GetLatestModelVersion","text":"<pre><code>GetLatestModelVersion(tracking_uri: str, model_name: str, **kwargs: Any)\n</code></pre> <p>               Bases: <code>BaseOperator</code></p> <p>Custom wrapper around MLFlowClient.search_model_versions.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>MLFlow tracking server uri</p> required <code>str</code> <p>name of MLFlow Model</p> required <code>Any</code> <p>BaseOperator kwargs</p> <code>{}</code> <p>Returns:</p> Type Description <code>None</code> <p>(dict) {\"version\": latest_version.version, \"run_id\": latest_version.run_id}</p>"},{"location":"reference/operators.mlflow/#dagcellent.operators.mlflow.GetLatestModelVersion(tracking_uri)","title":"<code>tracking_uri</code>","text":""},{"location":"reference/operators.mlflow/#dagcellent.operators.mlflow.GetLatestModelVersion(model_name)","title":"<code>model_name</code>","text":""},{"location":"reference/operators.mlflow/#dagcellent.operators.mlflow.GetLatestModelVersion(kwargs)","title":"<code>kwargs</code>","text":""},{"location":"reference/operators.mlflow/#dagcellent.operators.mlflow.GetModelMetaData","title":"GetModelMetaData","text":"<pre><code>GetModelMetaData(tracking_uri: str, upstream_task_id: str, **kwargs: Any)\n</code></pre> <p>               Bases: <code>BaseOperator</code></p> <p>Wrapper around MLFlowClient.get_run.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Mlflow.client tracking URI</p> required <code>str</code> <p>xcom which has <code>run_id</code> key.</p> required <code>Any</code> <p>BaseOperator args</p> <code>{}</code>"},{"location":"reference/operators.mlflow/#dagcellent.operators.mlflow.GetModelMetaData(tracking_uri)","title":"<code>tracking_uri</code>","text":""},{"location":"reference/operators.mlflow/#dagcellent.operators.mlflow.GetModelMetaData(upstream_task_id)","title":"<code>upstream_task_id</code>","text":""},{"location":"reference/operators.mlflow/#dagcellent.operators.mlflow.GetModelMetaData(kwargs)","title":"<code>kwargs</code>","text":""},{"location":"reference/operators.mlflow/#dagcellent.operators.mlflow.GetModelVersionByNameAndStage","title":"GetModelVersionByNameAndStage","text":"<pre><code>GetModelVersionByNameAndStage(tracking_uri: str, model_name: str, stage: MlflowModelStage, **kwargs: Any)\n</code></pre> <p>               Bases: <code>BaseOperator</code></p> <p>Wrapper around MLflow search_model_versions limited by name and tag.stage.</p> Example <pre><code># Get prod model run id\nfrom dagcellent.operators.mlflow import (\n    GetModelVersionByNameAndStage,\n    MlflowModelStage,\n)\n\nget_prod_run_id = GetModelVersionByNameAndStage(\n    task_id=\"get_prod_run_id\",\n    tracking_uri=\"&lt;login&gt;:&lt;password&gt;@&lt;domain&gt;/&lt;login&gt;/mlflow\",\n    model_name=\"&lt;skynet-auto&gt;\",\n    stage=MlflowModelStage.PRODUCTION,\n)\n</code></pre> <p>If no <code>stage</code> provided, returns the latest version for each stage.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Mlflow.client tracking URI</p> required <code>str</code> <p>MLFlow model name</p> required <code>MlflowModelStage</code> <p>target stage to transition to</p> required <code>Any</code> <p>BaseOperator args</p> <code>{}</code>"},{"location":"reference/operators.mlflow/#dagcellent.operators.mlflow.GetModelVersionByNameAndStage(tracking_uri)","title":"<code>tracking_uri</code>","text":""},{"location":"reference/operators.mlflow/#dagcellent.operators.mlflow.GetModelVersionByNameAndStage(model_name)","title":"<code>model_name</code>","text":""},{"location":"reference/operators.mlflow/#dagcellent.operators.mlflow.GetModelVersionByNameAndStage(stage)","title":"<code>stage</code>","text":""},{"location":"reference/operators.mlflow/#dagcellent.operators.mlflow.GetModelVersionByNameAndStage(kwargs)","title":"<code>kwargs</code>","text":""},{"location":"reference/operators.mlflow/#dagcellent.operators.mlflow.MlflowModelStage","title":"MlflowModelStage","text":"<p>               Bases: <code>Enum</code></p> <p>Allowed Mlflow 'stage' tag values.</p>"},{"location":"reference/operators.mlflow/#dagcellent.operators.mlflow.SetModelVersionTag","title":"SetModelVersionTag","text":"<pre><code>SetModelVersionTag(tracking_uri: str, model_name: str, version: str, tag: dict[str, str], **kwargs: Any)\n</code></pre> <p>               Bases: <code>BaseOperator</code></p> <p>Wrapper around MLFlowClient.set_model_version_tag.</p> <p>Tags have to be passed in as key-value pairs. Multiple tags can be set.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Mlflow.client tracking URI</p> required <code>str</code> <p>mlfow model name e.g.: <code>batch</code></p> required <code>str</code> <p>(str): model version</p> required <code>dict[str, str]</code> <p>arbitrary tag in <code>{key: value}</code> format</p> required <code>Any</code> <p>BaseOperator args</p> <code>{}</code>"},{"location":"reference/operators.mlflow/#dagcellent.operators.mlflow.SetModelVersionTag(tracking_uri)","title":"<code>tracking_uri</code>","text":""},{"location":"reference/operators.mlflow/#dagcellent.operators.mlflow.SetModelVersionTag(model_name)","title":"<code>model_name</code>","text":""},{"location":"reference/operators.mlflow/#dagcellent.operators.mlflow.SetModelVersionTag(version)","title":"<code>version</code>","text":""},{"location":"reference/operators.mlflow/#dagcellent.operators.mlflow.SetModelVersionTag(tag)","title":"<code>tag</code>","text":""},{"location":"reference/operators.mlflow/#dagcellent.operators.mlflow.SetModelVersionTag(kwargs)","title":"<code>kwargs</code>","text":""},{"location":"reference/operators.mlflow/#dagcellent.operators.mlflow.SlimModelVersion","title":"SlimModelVersion","text":"<p>               Bases: <code>TypedDict</code></p> <p>Slim, JSON serializable type of mlflow.entities.model_registry.ModelVersion.</p>"}]}