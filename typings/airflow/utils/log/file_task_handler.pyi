"""
This type stub file was generated by pyright.
"""

import logging
from enum import Enum
from functools import cached_property
from typing import TYPE_CHECKING

from airflow.models.taskinstance import TaskInstance
from airflow.utils.log.logging_mixin import SetContextPropagate

"""File logging handler for tasks."""
if TYPE_CHECKING: ...
logger = ...

class LogType(str, Enum):
    """
    Type of service from which we retrieve logs.

    :meta private:
    """

    TRIGGER = ...
    WORKER = ...

_parse_timestamp = ...
if not _parse_timestamp: ...

class FileTaskHandler(logging.Handler):
    """
    FileTaskHandler is a python log handler that handles and reads task instance logs.

    It creates and delegates log handling to `logging.FileHandler` after receiving task
    instance context.  It reads logs from task instance's host machine.

    :param base_log_folder: Base log folder to place logs.
    :param filename_template: template filename string
    :param max_bytes: max bytes size for the log file
    :param backup_count: backup file count for the log file
    :param delay:  default False -> StreamHandler, True -> Handler
    """

    trigger_should_wrap = ...
    inherits_from_empty_operator_log_message = ...
    def __init__(
        self,
        base_log_folder: str,
        filename_template: str | None = ...,
        max_bytes: int = ...,
        backup_count: int = ...,
        delay: bool = ...,
    ) -> None: ...
    def set_context(
        self, ti: TaskInstance, *, identifier: str | None = ...
    ) -> None | SetContextPropagate:
        """
        Provide task_instance context to airflow task handler.

        Generally speaking returns None.  But if attr `maintain_propagate` has
        been set to propagate, then returns sentinel MAINTAIN_PROPAGATE. This
        has the effect of overriding the default behavior to set `propagate`
        to False whenever set_context is called.  At time of writing, this
        functionality is only used in unit testing.

        :param ti: task instance object
        :param identifier: if set, adds suffix to log file. For use when relaying exceptional messages
            to task logs from a context other than task or trigger run
        """
        ...

    @cached_property
    def supports_task_context_logging(self) -> bool: ...
    @staticmethod
    def add_triggerer_suffix(full_path, job_id=...):  # -> str:
        """
        Derive trigger log filename from task log filename.

        E.g. given /path/to/file.log returns /path/to/file.log.trigger.123.log, where 123
        is the triggerer id.  We use the triggerer ID instead of trigger ID to distinguish
        the files because, rarely, the same trigger could get picked up by two different
        triggerer instances.
        """
        ...

    def emit(self, record):  # -> None:
        ...
    def flush(self):  # -> None:
        ...
    def close(self):  # -> None:
        ...
    def read(
        self, task_instance, try_number=..., metadata=...
    ):  # -> tuple[list[list[tuple[str, str]]], list[dict[str, bool]]] | tuple[list[str], list[dict[Any, Any]]]:
        """
        Read logs of given task instance from local machine.

        :param task_instance: task instance object
        :param try_number: task instance try_number to read logs from. If None
                           it returns all logs separated by try_number
        :param metadata: log metadata, can be used for steaming log reading and auto-tailing.
        :return: a list of listed tuples which order log string by host
        """
        ...
