"""
This type stub file was generated by pyright.
"""

from collections.abc import Iterable
from datetime import datetime
from typing import TYPE_CHECKING, Annotated, Any

import pendulum
from airflow.exceptions import TaskDeferred
from airflow.models import Operator
from airflow.models.baseoperator import BaseOperator
from airflow.models.dagrun import DagRun
from airflow.models.taskinstance import TaskInstance
from airflow.serialization.pydantic.dag import DagModelPydantic
from airflow.serialization.pydantic.dag_run import DagRunPydantic
from airflow.utils.context import Context
from airflow.utils.log.logging_mixin import LoggingMixin
from airflow.utils.pydantic import (
    BaseModel as BaseModelPydantic,
    PlainSerializer,
    PlainValidator,
    ValidationInfo,
    is_pydantic_2_installed,
)
from airflow.utils.state import DagRunState
from sqlalchemy.orm import Session

if TYPE_CHECKING: ...

def serialize_operator(x: Operator | None) -> dict | None: ...
def validated_operator(x: dict[str, Any] | Operator, _info: ValidationInfo) -> Any: ...

PydanticOperator = Annotated[
    Operator,
    PlainValidator(validated_operator),
    PlainSerializer(serialize_operator, return_type=dict),
]

class TaskInstancePydantic(BaseModelPydantic, LoggingMixin):
    """Serializable representation of the TaskInstance ORM SqlAlchemyModel used by internal API."""

    task_id: str
    dag_id: str
    run_id: str
    map_index: int
    start_date: datetime | None
    end_date: datetime | None
    execution_date: datetime | None
    duration: float | None
    state: str | None
    try_number: int
    max_tries: int
    hostname: str
    unixname: str
    job_id: int | None
    pool: str
    pool_slots: int
    queue: str
    priority_weight: int | None
    operator: str
    custom_operator_name: str | None
    queued_dttm: datetime | None
    queued_by_job_id: int | None
    pid: int | None
    executor: str | None
    executor_config: Any
    updated_at: datetime | None
    rendered_map_index: str | None
    external_executor_id: str | None
    trigger_id: int | None
    trigger_timeout: datetime | None
    next_method: str | None
    next_kwargs: dict | None
    run_as_user: str | None
    task: PydanticOperator | None
    test_mode: bool
    dag_run: DagRunPydantic | None
    dag_model: DagModelPydantic | None
    raw: bool | None
    is_trigger_log_context: bool | None
    model_config = ...
    def clear_xcom_data(self, session: Session | None = ...):  # -> None:
        ...
    def set_state(self, state, session: Session | None = ...) -> bool: ...
    def render_templates(
        self, context: Context | None = ..., jinja_env=...
    ):  # -> Operator:
        ...
    def init_run_context(self, raw: bool = ...) -> None:
        """Set the log context."""
        ...

    def xcom_pull(
        self,
        task_ids: str | Iterable[str] | None = ...,
        dag_id: str | None = ...,
        key: str = ...,
        include_prior_dates: bool = ...,
        session: Session | None = ...,
        *,
        map_indexes: int | Iterable[int] | None = ...,
        default: Any = ...,
    ) -> Any:
        """
        Pull an XCom value for this task instance.

        :param task_ids: task id or list of task ids, if None, the task_id of the current task is used
        :param dag_id: dag id, if None, the dag_id of the current task is used
        :param key: the key to identify the XCom value
        :param include_prior_dates: whether to include prior execution dates
        :param session: the sqlalchemy session
        :param map_indexes: map index or list of map indexes, if None, the map_index of the current task
            is used
        :param default: the default value to return if the XCom value does not exist
        :return: Xcom value
        """
        ...

    def xcom_push(
        self,
        key: str,
        value: Any,
        execution_date: datetime | None = ...,
        session: Session | None = ...,
    ) -> None:
        """
        Push an XCom value for this task instance.

        :param key: the key to identify the XCom value
        :param value: the value of the XCom
        :param execution_date: the execution date to push the XCom for
        """
        ...

    def get_dagrun(self, session: Session | None = ...) -> DagRunPydantic:
        """
        Return the DagRun for this TaskInstance.

        :param session: SQLAlchemy ORM Session

        :return: Pydantic serialized version of DagRun
        """
        ...

    def refresh_from_db(
        self, session: Session | None = ..., lock_for_update: bool = ...
    ) -> None:
        """
        Refresh the task instance from the database based on the primary key.

        :param session: SQLAlchemy ORM Session
        :param lock_for_update: if True, indicates that the database should
            lock the TaskInstance (issuing a FOR UPDATE clause) until the
            session is committed.
        """
        ...

    def set_duration(self) -> None:
        """Set task instance duration."""
        ...

    @property
    def stats_tags(self) -> dict[str, str]:
        """Return task instance tags."""
        ...

    def clear_next_method_args(self) -> None:
        """Ensure we unset next_method and next_kwargs to ensure that any retries don't reuse them."""
        ...

    def get_template_context(
        self, session: Session | None = ..., ignore_param_exceptions: bool = ...
    ) -> Context:
        """
        Return TI Context.

        :param session: SQLAlchemy ORM Session
        :param ignore_param_exceptions: flag to suppress value exceptions while initializing the ParamsDict
        """
        ...

    def is_eligible_to_retry(self):  # -> bool | Literal[0] | None:
        """Is task instance is eligible for retry."""
        ...

    def handle_failure(
        self,
        error: None | str | BaseException,
        test_mode: bool | None = ...,
        context: Context | None = ...,
        force_fail: bool = ...,
        session: Session | None = ...,
    ) -> None:
        """
        Handle Failure for a task instance.

        :param error: if specified, log the specific exception if thrown
        :param session: SQLAlchemy ORM Session
        :param test_mode: doesn't record success or failure in the DB if True
        :param context: Jinja2 context
        :param force_fail: if True, task does not retry
        """
        ...

    def refresh_from_task(
        self, task: Operator, pool_override: str | None = ...
    ) -> None:
        """
        Copy common attributes from the given task.

        :param task: The task object to copy from
        :param pool_override: Use the pool_override instead of task's pool
        """
        ...

    def get_previous_dagrun(
        self, state: DagRunState | None = ..., session: Session | None = ...
    ) -> DagRun | None:
        """
        Return the DagRun that ran before this task instance's DagRun.

        :param state: If passed, it only take into account instances of a specific state.
        :param session: SQLAlchemy ORM Session.
        """
        ...

    def get_previous_execution_date(
        self, state: DagRunState | None = ..., session: Session | None = ...
    ) -> pendulum.DateTime | None:
        """
        Return the execution date from property previous_ti_success.

        :param state: If passed, it only take into account instances of a specific state.
        :param session: SQLAlchemy ORM Session
        """
        ...

    def get_previous_start_date(
        self, state: DagRunState | None = ..., session: Session | None = ...
    ) -> pendulum.DateTime | None:
        """
        Return the execution date from property previous_ti_success.

        :param state: If passed, it only take into account instances of a specific state.
        :param session: SQLAlchemy ORM Session
        """
        ...

    def email_alert(self, exception, task: BaseOperator) -> None:
        """
        Send alert email with exception information.

        :param exception: the exception
        :param task: task related to the exception
        """
        ...

    def get_email_subject_content(
        self, exception: BaseException, task: BaseOperator | None = ...
    ) -> tuple[str, str, str]:
        """
        Get the email subject content for exceptions.

        :param exception: the exception sent in the email
        :param task:
        """
        ...

    def get_previous_ti(
        self, state: DagRunState | None = ..., session: Session | None = ...
    ) -> TaskInstance | TaskInstancePydantic | None:
        """
        Return the task instance for the task that ran before this task instance.

        :param session: SQLAlchemy ORM Session
        :param state: If passed, it only take into account instances of a specific state.
        """
        ...

    def check_and_change_state_before_execution(
        self,
        verbose: bool = ...,
        ignore_all_deps: bool = ...,
        ignore_depends_on_past: bool = ...,
        wait_for_past_depends_before_skipping: bool = ...,
        ignore_task_deps: bool = ...,
        ignore_ti_state: bool = ...,
        mark_success: bool = ...,
        test_mode: bool = ...,
        job_id: str | None = ...,
        pool: str | None = ...,
        external_executor_id: str | None = ...,
        session: Session | None = ...,
    ) -> bool: ...
    def schedule_downstream_tasks(
        self, session: Session | None = ..., max_tis_per_query: int | None = ...
    ):  # -> None:
        """
        Schedule downstream tasks of this task instance.

        :meta: private
        """
        ...

    def command_as_list(
        self,
        mark_success: bool = ...,
        ignore_all_deps: bool = ...,
        ignore_task_deps: bool = ...,
        ignore_depends_on_past: bool = ...,
        wait_for_past_depends_before_skipping: bool = ...,
        ignore_ti_state: bool = ...,
        local: bool = ...,
        pickle_id: int | None = ...,
        raw: bool = ...,
        job_id: str | None = ...,
        pool: str | None = ...,
        cfg_path: str | None = ...,
    ) -> list[str]:
        """
        Return a command that can be executed anywhere where airflow is installed.

        This command is part of the message sent to executors by the orchestrator.
        """
        ...

    def defer_task(
        self, exception: TaskDeferred, session: Session | None = ...
    ):  # -> None:
        """Defer task."""
        ...

    def get_relevant_upstream_map_indexes(
        self, upstream: Operator, ti_count: int | None, *, session: Session | None = ...
    ) -> int | range | None: ...

if is_pydantic_2_installed(): ...
