"""
This type stub file was generated by pyright.
"""

from typing import TYPE_CHECKING

import attr
import pendulum
from airflow.jobs.base_job_runner import BaseJobRunner
from airflow.jobs.job import Job
from airflow.models import DAG
from airflow.models.dagrun import DagRun
from airflow.models.taskinstance import TaskInstance, TaskInstanceKey
from airflow.utils.log.logging_mixin import LoggingMixin
from airflow.utils.session import provide_session
from sqlalchemy.orm.session import Session

if TYPE_CHECKING: ...

class BackfillJobRunner(BaseJobRunner, LoggingMixin):
    """
    A backfill job runner consists of a dag or subdag for a specific time range.

    It triggers a set of task instance runs, in the right order and lasts for
    as long as it takes for the set of task instance to be completed.
    """

    job_type = ...
    STATES_COUNT_AS_RUNNING = ...
    @attr.define
    class _DagRunTaskStatus:
        """
        Internal status of the backfill job.

        This class is intended to be instantiated only within a BackfillJobRunner
        instance and will track the execution of tasks, e.g. running, skipped,
        succeeded, failed, etc. Information about the dag runs related to the
        backfill job are also being tracked in this structure, e.g. finished runs, etc.
        Any other status related information related to the execution of dag runs / tasks
        can be included in this structure since it makes it easier to pass it around.

        :param to_run: Tasks to run in the backfill
        :param running: Maps running task instance key to task instance object
        :param skipped: Tasks that have been skipped
        :param succeeded: Tasks that have succeeded so far
        :param failed: Tasks that have failed
        :param not_ready: Tasks not ready for execution
        :param deadlocked: Deadlocked tasks
        :param active_runs: Active dag runs at a certain point in time
        :param executed_dag_run_dates: Datetime objects for the executed dag runs
        :param finished_runs: Number of finished runs so far
        :param total_runs: Number of total dag runs able to run
        """

        to_run: dict[TaskInstanceKey, TaskInstance] = ...
        running: dict[TaskInstanceKey, TaskInstance] = ...
        skipped: set[TaskInstanceKey] = ...
        succeeded: set[TaskInstanceKey] = ...
        failed: set[TaskInstanceKey] = ...
        not_ready: set[TaskInstanceKey] = ...
        deadlocked: set[TaskInstance] = ...
        active_runs: set[DagRun] = ...
        executed_dag_run_dates: set[pendulum.DateTime] = ...
        finished_runs: int = ...
        total_runs: int = ...

    def __init__(
        self,
        job: Job,
        dag: DAG,
        start_date=...,
        end_date=...,
        mark_success=...,
        donot_pickle=...,
        ignore_first_depends_on_past=...,
        ignore_task_deps=...,
        pool=...,
        delay_on_limit_secs=...,
        verbose=...,
        conf=...,
        rerun_failed_tasks=...,
        run_backwards=...,
        run_at_least_once=...,
        continue_on_failures=...,
        disable_retry=...,
    ) -> None:
        """
        Create a BackfillJobRunner.

        :param dag: DAG object.
        :param start_date: start date for the backfill date range.
        :param end_date: end date for the backfill date range.
        :param mark_success: flag whether to mark the task auto success.
        :param donot_pickle: whether pickle
        :param ignore_first_depends_on_past: whether to ignore depend on past
        :param ignore_task_deps: whether to ignore the task dependency
        :param pool: pool to backfill
        :param delay_on_limit_secs:
        :param verbose:
        :param conf: a dictionary which user could pass k-v pairs for backfill
        :param rerun_failed_tasks: flag to whether to
                                   auto rerun the failed task in backfill
        :param run_backwards: Whether to process the dates from most to least recent
        :param run_at_least_once: If true, always run the DAG at least once even
            if no logical run exists within the time range.
        :param args:
        :param kwargs:
        """
        ...

    @provide_session
    def reset_state_for_orphaned_tasks(
        self, filter_by_dag_run: DagRun | None = ..., session: Session = ...
    ) -> int | None:
        """
        Reset state of orphaned tasks.

        This function checks if there are any tasks in the dagrun (or all) that
        have a schedule or queued states but are not known by the executor. If
        it finds those it will reset the state to None so they will get picked
        up again.  The batch option is for performance reasons as the queries
        are made in sequence.

        :param filter_by_dag_run: the dag_run we want to process, None if all
        :return: the number of TIs reset
        """
        ...
