"""
This type stub file was generated by pyright.
"""

import datetime
from collections.abc import Iterable
from typing import TYPE_CHECKING, Any

from airflow.api_internal.internal_api_call import internal_api_call
from airflow.models.base import Base
from airflow.serialization.pydantic.trigger import TriggerPydantic
from airflow.triggers.base import BaseTrigger
from airflow.utils.session import provide_session
from sqlalchemy.orm import Session
from sqlalchemy.sql import Select

if TYPE_CHECKING: ...

class Trigger(Base):
    """
    Base Trigger class.

    Triggers are a workload that run in an asynchronous event loop shared with
    other Triggers, and fire off events that will unpause deferred Tasks,
    start linked DAGs, etc.

    They are persisted into the database and then re-hydrated into a
    "triggerer" process, where many are run at once. We model it so that
    there is a many-to-one relationship between Task and Trigger, for future
    deduplication logic to use.

    Rows will be evicted from the database when the triggerer detects no
    active Tasks/DAGs using them. Events are not stored in the database;
    when an Event is fired, the triggerer will directly push its data to the
    appropriate Task/DAG.
    """

    __tablename__ = ...
    id = ...
    classpath = ...
    encrypted_kwargs = ...
    created_date = ...
    triggerer_id = ...
    triggerer_job = ...
    task_instance = ...
    def __init__(
        self,
        classpath: str,
        kwargs: dict[str, Any],
        created_date: datetime.datetime | None = ...,
    ) -> None: ...
    @property
    def kwargs(self) -> dict[str, Any]:
        """Return the decrypted kwargs of the trigger."""
        ...

    @kwargs.setter
    def kwargs(self, kwargs: dict[str, Any]) -> None:
        """Set the encrypted kwargs of the trigger."""
        ...

    def rotate_fernet_key(self):  # -> None:
        """Encrypts data with a new key. See: :ref:`security/fernet`."""
        ...

    @classmethod
    @internal_api_call
    @provide_session
    def from_object(
        cls, trigger: BaseTrigger, session=...
    ) -> Trigger | TriggerPydantic:
        """Alternative constructor that creates a trigger row based directly off of a Trigger object."""
        ...

    @classmethod
    @internal_api_call
    @provide_session
    def bulk_fetch(
        cls, ids: Iterable[int], session: Session = ...
    ) -> dict[int, Trigger]:
        """Fetch all the Triggers by ID and return a dict mapping ID -> Trigger instance."""
        ...

    @classmethod
    @internal_api_call
    @provide_session
    def clean_unused(cls, session: Session = ...) -> None:
        """
        Delete all triggers that have no tasks dependent on them.

        Triggers have a one-to-many relationship to task instances, so we need
        to clean those up first. Afterwards we can drop the triggers not
        referenced by anyone.
        """
        ...

    @classmethod
    @internal_api_call
    @provide_session
    def submit_event(cls, trigger_id, event, session: Session = ...) -> None:
        """Take an event from an instance of itself, and trigger all dependent tasks to resume."""
        ...

    @classmethod
    @internal_api_call
    @provide_session
    def submit_failure(cls, trigger_id, exc=..., session: Session = ...) -> None:
        """
        When a trigger has failed unexpectedly, mark everything that depended on it as failed.

        Notably, we have to actually run the failure code from a worker as it may
        have linked callbacks, so hilariously we have to re-schedule the task
        instances to a worker just so they can then fail.

        We use a special __fail__ value for next_method to achieve this that
        the runtime code understands as immediate-fail, and pack the error into
        next_kwargs.

        TODO: Once we have shifted callback (and email) handling to run on
        workers as first-class concepts, we can run the failure code here
        in-process, but we can't do that right now.
        """
        ...

    @classmethod
    @internal_api_call
    @provide_session
    def ids_for_triggerer(cls, triggerer_id, session: Session = ...) -> list[int]:
        """Retrieve a list of triggerer_ids."""
        ...

    @classmethod
    @internal_api_call
    @provide_session
    def assign_unassigned(
        cls, triggerer_id, capacity, health_check_threshold, session: Session = ...
    ) -> None:
        """
        Assign unassigned triggers based on a number of conditions.

        Takes a triggerer_id, the capacity for that triggerer and the Triggerer job heartrate
        health check threshold, and assigns unassigned triggers until that capacity is reached,
        or there are no more unassigned triggers.
        """
        ...

    @classmethod
    def get_sorted_triggers(
        cls, capacity: int, alive_triggerer_ids: list[int] | Select, session: Session
    ):
        """
        Get sorted triggers based on capacity and alive triggerer ids.

        :param capacity: The capacity of the triggerer.
        :param alive_triggerer_ids: The alive triggerer ids as a list or a select query.
        :param session: The database session.
        """
        ...
