"""
This type stub file was generated by pyright.
"""

from datetime import timedelta
from pathlib import Path
from typing import TYPE_CHECKING, NamedTuple

from airflow.models.base import Base
from airflow.utils.log.logging_mixin import LoggingMixin
from airflow.utils.session import provide_session
from airflow.utils.types import ArgNotSet
from sqlalchemy.orm import Session

if TYPE_CHECKING: ...

class FileLoadStat(NamedTuple):
    """
    Information about single file.

    :param file: Loaded file.
    :param duration: Time spent on process file.
    :param dag_num: Total number of DAGs loaded in this file.
    :param task_num: Total number of Tasks loaded in this file.
    :param dags: DAGs names loaded in this file.
    :param warning_num: Total number of warnings captured from processing this file.
    """

    file: str
    duration: timedelta
    dag_num: int
    task_num: int
    dags: str
    warning_num: int
    ...

class DagBag(LoggingMixin):
    """
    A dagbag is a collection of dags, parsed out of a folder tree and has high level configuration settings.

    Some possible setting are database to use as a backend and what executor
    to use to fire off tasks. This makes it easier to run distinct environments
    for say production and development, tests, or for different teams or security
    profiles. What would have been system level settings are now dagbag level so
    that one system can run multiple, independent settings sets.

    :param dag_folder: the folder to scan to find DAGs
    :param include_examples: whether to include the examples that ship
        with airflow or not
    :param safe_mode: when ``False``, scans all python modules for dags.
        When ``True`` uses heuristics (files containing ``DAG`` and ``airflow`` strings)
        to filter python modules to scan for dags.
    :param read_dags_from_db: Read DAGs from DB if ``True`` is passed.
        If ``False`` DAGs are read from python files.
    :param store_serialized_dags: deprecated parameter, same effect as `read_dags_from_db`
    :param load_op_links: Should the extra operator link be loaded via plugins when
        de-serializing the DAG? This flag is set to False in Scheduler so that Extra Operator links
        are not loaded to not run User code in Scheduler.
    :param collect_dags: when True, collects dags during class initialization.
    """

    def __init__(
        self,
        dag_folder: str | Path | None = ...,
        include_examples: bool | ArgNotSet = ...,
        safe_mode: bool | ArgNotSet = ...,
        read_dags_from_db: bool = ...,
        store_serialized_dags: bool | None = ...,
        load_op_links: bool = ...,
        collect_dags: bool = ...,
    ) -> None: ...
    def size(self) -> int:
        """:return: the amount of dags contained in this dagbag"""
        ...

    @property
    def store_serialized_dags(self) -> bool:
        """Whether to read dags from DB."""
        ...

    @property
    def dag_ids(self) -> list[str]:
        """
        Get DAG ids.

        :return: a list of DAG IDs in this bag
        """
        ...

    @provide_session
    def get_dag(self, dag_id, session: Session = ...):  # -> DAG | None:
        """
        Get the DAG out of the dictionary, and refreshes it if expired.

        :param dag_id: DAG ID
        """
        ...

    def process_file(
        self, filepath, only_if_updated=..., safe_mode=...
    ):  # -> list[Any]:
        """Given a path to a python module or zip file, import the module and look for dag objects within."""
        ...

    def bag_dag(self, dag, root_dag):  # -> None:
        """
        Add the DAG into the bag, recurses into sub dags.

        :raises: AirflowDagCycleException if a cycle is detected in this dag or its subdags.
        :raises: AirflowDagDuplicatedIdException if this dag or its subdags already exists in the bag.
        """
        ...

    def collect_dags(
        self,
        dag_folder: str | Path | None = ...,
        only_if_updated: bool = ...,
        include_examples: bool = ...,
        safe_mode: bool = ...,
    ):  # -> None:
        """
        Look for python modules in a given path, import them, and add them to the dagbag collection.

        Note that if a ``.airflowignore`` file is found while processing
        the directory, it will behave much like a ``.gitignore``,
        ignoring files that match any of the patterns specified
        in the file.

        **Note**: The patterns in ``.airflowignore`` are interpreted as either
        un-anchored regexes or gitignore-like glob expressions, depending on
        the ``DAG_IGNORE_FILE_SYNTAX`` configuration parameter.
        """
        ...

    def collect_dags_from_db(self):  # -> None:
        """Collect DAGs from database."""
        ...

    def dagbag_report(self):  # -> str:
        """Print a report around DagBag loading stats."""
        ...

    @provide_session
    def sync_to_db(
        self, processor_subdir: str | None = ..., session: Session = ...
    ):  # -> None:
        ...

def generate_md5_hash(context):  # -> str:
    ...

class DagPriorityParsingRequest(Base):
    """Model to store the dag parsing requests that will be prioritized when parsing files."""

    __tablename__ = ...
    id = ...
    fileloc = ...
    def __init__(self, fileloc: str) -> None: ...
    def __repr__(self) -> str: ...
