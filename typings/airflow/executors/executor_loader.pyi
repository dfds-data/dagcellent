"""
This type stub file was generated by pyright.
"""

import functools
from typing import TYPE_CHECKING

from airflow.executors.base_executor import BaseExecutor
from airflow.executors.executor_constants import ConnectorSource
from airflow.executors.executor_utils import ExecutorName

"""All executors."""
log = ...
if TYPE_CHECKING: ...
_alias_to_executors: dict[str, ExecutorName] = ...
_module_to_executors: dict[str, ExecutorName] = ...
_classname_to_executors: dict[str, ExecutorName] = ...
_executor_names: list[ExecutorName] = ...
_loaded_executors: dict[ExecutorName, BaseExecutor] = ...

class ExecutorLoader:
    """Keeps constants for all the currently available executors."""

    executors = ...
    @classmethod
    def get_executor_names(cls) -> list[ExecutorName]:
        """
        Return the executor names from Airflow configuration.

        :return: List of executor names from Airflow configuration
        """
        ...

    @classmethod
    def get_default_executor_name(cls) -> ExecutorName:
        """
        Return the default executor name from Airflow configuration.

        :return: executor name from Airflow configuration
        """
        ...

    @classmethod
    def get_default_executor(cls) -> BaseExecutor:
        """Create a new instance of the configured executor if none exists and returns it."""
        ...

    @classmethod
    def set_default_executor(cls, executor: BaseExecutor) -> None:
        """
        Externally set an executor to be the default.

        This is used in rare cases such as dag.run which allows, as a user convenience, to provide
        the executor by cli/argument instead of Airflow configuration
        """
        ...

    @classmethod
    def init_executors(cls) -> list[BaseExecutor]:
        """Create a new instance of all configured executors if not cached already."""
        ...

    @classmethod
    def lookup_executor_name_by_str(cls, executor_name_str: str) -> ExecutorName: ...
    @classmethod
    def load_executor(cls, executor_name: ExecutorName | str | None) -> BaseExecutor:
        """
        Load the executor.

        This supports the following formats:
        * by executor name for core executor
        * by ``{plugin_name}.{class_name}`` for executor from plugins
        * by import path
        * by class name of the Executor
        * by ExecutorName object specification

        :return: an instance of executor class via executor_name
        """
        ...

    @classmethod
    def import_executor_cls(
        cls, executor_name: ExecutorName, validate: bool = ...
    ) -> tuple[type[BaseExecutor], ConnectorSource]:
        """
        Import the executor class.

        Supports the same formats as ExecutorLoader.load_executor.

        :param executor_name: Name of core executor or module path to provider provided as a plugin.
        :param validate: Whether or not to validate the executor before returning

        :return: executor class via executor_name and executor import source
        """
        ...

    @classmethod
    def import_default_executor_cls(
        cls, validate: bool = ...
    ) -> tuple[type[BaseExecutor], ConnectorSource]:
        """
        Import the default executor class.

        :param validate: Whether or not to validate the executor before returning

        :return: executor class and executor import source
        """
        ...

    @classmethod
    @functools.cache
    def validate_database_executor_compatibility(
        cls, executor: type[BaseExecutor]
    ) -> None:
        """
        Validate database and executor compatibility.

        Most of the databases work universally, but SQLite can only work with
        single-threaded executors (e.g. Sequential).

        This is NOT done in ``airflow.configuration`` (when configuration is
        initialized) because loading the executor class is heavy work we want to
        avoid unless needed.
        """
        ...

UNPICKLEABLE_EXECUTORS = ...
